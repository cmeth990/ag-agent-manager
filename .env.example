# Place this file as .env in the project root (ag-agent-manager/).
# The app loads .env from project root so API keys work when run from any directory.
# Telegram Bot Configuration
TELEGRAM_BOT_TOKEN=

# Database Configuration
# For local development, use a local Postgres instance
# For Railway, the DATABASE_URL will be auto-injected by the Postgres service
DATABASE_URL=postgresql://user:password@localhost:5432/dbname

# Optional: Model API Keys (at least one for extraction, improve, gather, etc.)
# OPENAI_API_KEY=your_key_here (recommended: cheapest with GPT-4o-mini)
# OPENAI_MODEL=gpt-4o-mini (default)
# ANTHROPIC_API_KEY=your_key_here (alternative to OpenAI)
# Kimi/Moonshot: cheaper, OpenAI-compatible, global endpoint (no China); zero-data-retention workflows exist
# MOONSHOT_API_KEY=your_key_here  (or KIMI_API_KEY)
# MOONSHOT_MODEL=moonshot-v1-8k (default; also moonshot-v1-32k, moonshot-v1-128k)

# Neo4j Configuration (for knowledge graph storage)
# NEO4J_URI=bolt://localhost:7687
# NEO4J_USER=neo4j
# NEO4J_PASSWORD=your_password_here

# Optional: Server Configuration
PORT=8000
RELOAD=false
# LangGraph: app sets default 30 to avoid 10000-step loop; override if needed
# LANGGRAPH_DEFAULT_RECURSION_LIMIT=30

# Optional: Production (Railway)
# USE_DURABLE_QUEUE=true
# ADMIN_API_KEY=your_secret_key_here
# PUBLIC_URL=https://your-app.up.railway.app  (for /graph progress link)
# GRAPH_VIEW_SECRET=optional_secret_for_progress_link  (or reuse ADMIN_API_KEY)

# Talk: voice messages (transcribe with Whisper, optional TTS reply)
# OPENAI_API_KEY required for transcribe + TTS
# TALK_REPLY_VOICE=true  (optional: reply with voice via OpenAI TTS)
# TALK_CONVERSATIONAL=true  (optional: add "What next?" to replies for hands-free conversation)
# TTS_MODEL=tts-1  (optional; default tts-1)
# TTS_VOICE=alloy  (optional; alloy, echo, fable, onyx, nova, shimmer)

# Live voice call: link the bot sends when user says "live call" or "start call"
# LIVE_CALL_URL=https://meet.jit.si/lumi-superintendent-911
